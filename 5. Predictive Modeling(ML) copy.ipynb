{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume($)</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Daily Return</th>\n",
       "      <th>SMA_30</th>\n",
       "      <th>SMA_60</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_rolling_std_7</th>\n",
       "      <th>Volume_rolling_mean_7</th>\n",
       "      <th>Volume_rolling_std_7</th>\n",
       "      <th>Close_rolling_mean_30</th>\n",
       "      <th>Close_rolling_std_30</th>\n",
       "      <th>Volume_rolling_mean_30</th>\n",
       "      <th>Volume_rolling_std_30</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28994.009766</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>40730301359</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>19715.608773</td>\n",
       "      <td>...</td>\n",
       "      <td>1284.059118</td>\n",
       "      <td>4.970113e+10</td>\n",
       "      <td>8.115395e+09</td>\n",
       "      <td>22428.243750</td>\n",
       "      <td>3661.566866</td>\n",
       "      <td>3.886562e+10</td>\n",
       "      <td>1.223869e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29376.455078</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>67865420765</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.093726</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>20018.558219</td>\n",
       "      <td>...</td>\n",
       "      <td>1936.633106</td>\n",
       "      <td>5.249153e+10</td>\n",
       "      <td>1.055716e+10</td>\n",
       "      <td>22850.972721</td>\n",
       "      <td>4019.854985</td>\n",
       "      <td>4.006346e+10</td>\n",
       "      <td>1.325301e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32129.408203</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>78665235202</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>20329.363493</td>\n",
       "      <td>...</td>\n",
       "      <td>2189.909798</td>\n",
       "      <td>5.423229e+10</td>\n",
       "      <td>1.376529e+10</td>\n",
       "      <td>23320.381315</td>\n",
       "      <td>4328.735995</td>\n",
       "      <td>4.155655e+10</td>\n",
       "      <td>1.494648e+10</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open          High           Low         Close     Adj Close  \\\n",
       "0  28994.009766  29600.626953  28803.585938  29374.152344  29374.152344   \n",
       "1  29376.455078  33155.117188  29091.181641  32127.267578  32127.267578   \n",
       "2  32129.408203  34608.558594  32052.316406  32782.023438  32782.023438   \n",
       "\n",
       "     Volume($) Symbol  Daily Return        SMA_30        SMA_60  ...  \\\n",
       "0  40730301359    BTC      0.012842  22428.243750  19715.608773  ...   \n",
       "1  67865420765    BTC      0.093726  22850.972721  20018.558219  ...   \n",
       "2  78665235202    BTC      0.020380  23320.381315  20329.363493  ...   \n",
       "\n",
       "   Close_rolling_std_7  Volume_rolling_mean_7  Volume_rolling_std_7  \\\n",
       "0          1284.059118           4.970113e+10          8.115395e+09   \n",
       "1          1936.633106           5.249153e+10          1.055716e+10   \n",
       "2          2189.909798           5.423229e+10          1.376529e+10   \n",
       "\n",
       "   Close_rolling_mean_30  Close_rolling_std_30  Volume_rolling_mean_30  \\\n",
       "0           22428.243750           3661.566866            3.886562e+10   \n",
       "1           22850.972721           4019.854985            4.006346e+10   \n",
       "2           23320.381315           4328.735995            4.155655e+10   \n",
       "\n",
       "   Volume_rolling_std_30  Year  Month  Day  \n",
       "0           1.223869e+10  2021      1    1  \n",
       "1           1.325301e+10  2021      1    2  \n",
       "2           1.494648e+10  2021      1    3  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/df_ml.csv', sep=\",\")\n",
    "#df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "#df.drop(index=1, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allowed_cryptos = ['BTC', 'ETH', 'USDT', 'BNB', 'SOL', 'XRP', 'ADA', 'AVAX', 'DOGE']\n",
    "# Filter the DataFrame to include only the rows with symbols in the allowed list\n",
    "#df = df[df['Symbol'].isin(allowed_cryptos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Symbol','Close', 'Close_lag_1', 'Low','Midpoint','High','Open','Close_lag_3']] #\n",
    "#df = df[['Close','Symbol','Close_lag_7','EMA_90', '90_day_MA', 'Close_rolling_mean_30','EMA_60','EMA_26','SMA_30']]\n",
    "#df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "28             Close_lag_7        1\n",
    "12                  EMA_90        1\n",
    "23               90_day_MA        1\n",
    "34   Close_rolling_mean_30        1\n",
    "11                  EMA_60        2\n",
    "15                  EMA_26        3\n",
    "7                   SMA_30        4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTC</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29001.720703</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29202.106445</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28994.009766</td>\n",
       "      <td>27362.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>31123.149414</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29376.455078</td>\n",
       "      <td>28840.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTC</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>33330.437500</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32129.408203</td>\n",
       "      <td>29001.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTC</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>28722.755859</td>\n",
       "      <td>31081.487305</td>\n",
       "      <td>33440.218750</td>\n",
       "      <td>32810.949219</td>\n",
       "      <td>29374.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BTC</td>\n",
       "      <td>33992.429688</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>30221.187500</td>\n",
       "      <td>32329.388672</td>\n",
       "      <td>34437.589844</td>\n",
       "      <td>31977.041016</td>\n",
       "      <td>32127.267578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.135291</td>\n",
       "      <td>2.101517</td>\n",
       "      <td>2.132578</td>\n",
       "      <td>2.163639</td>\n",
       "      <td>2.143799</td>\n",
       "      <td>2.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.156239</td>\n",
       "      <td>2.397342</td>\n",
       "      <td>2.638445</td>\n",
       "      <td>2.159645</td>\n",
       "      <td>2.092255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16041</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.424762</td>\n",
       "      <td>2.578523</td>\n",
       "      <td>2.732283</td>\n",
       "      <td>2.592313</td>\n",
       "      <td>2.135291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.418916</td>\n",
       "      <td>2.483391</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>2.544140</td>\n",
       "      <td>2.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16043</th>\n",
       "      <td>TON</td>\n",
       "      <td>2.344989</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.287904</td>\n",
       "      <td>2.356607</td>\n",
       "      <td>2.425310</td>\n",
       "      <td>2.425128</td>\n",
       "      <td>2.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol         Close   Close_lag_1           Low      Midpoint  \\\n",
       "0        BTC  29374.152344  29001.720703  28803.585938  29202.106445   \n",
       "1        BTC  32127.267578  29374.152344  29091.181641  31123.149414   \n",
       "2        BTC  32782.023438  32127.267578  32052.316406  33330.437500   \n",
       "3        BTC  31971.914062  32782.023438  28722.755859  31081.487305   \n",
       "4        BTC  33992.429688  31971.914062  30221.187500  32329.388672   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "16039    TON      2.160291      2.135291      2.101517      2.132578   \n",
       "16040    TON      2.587086      2.160291      2.156239      2.397342   \n",
       "16041    TON      2.539670      2.587086      2.424762      2.578523   \n",
       "16042    TON      2.425865      2.539670      2.418916      2.483391   \n",
       "16043    TON      2.344989      2.425865      2.287904      2.356607   \n",
       "\n",
       "               High          Open   Close_lag_3  \n",
       "0      29600.626953  28994.009766  27362.437500  \n",
       "1      33155.117188  29376.455078  28840.953125  \n",
       "2      34608.558594  32129.408203  29001.720703  \n",
       "3      33440.218750  32810.949219  29374.152344  \n",
       "4      34437.589844  31977.041016  32127.267578  \n",
       "...             ...           ...           ...  \n",
       "16039      2.163639      2.143799      2.045980  \n",
       "16040      2.638445      2.159645      2.092255  \n",
       "16041      2.732283      2.592313      2.135291  \n",
       "16042      2.547866      2.544140      2.160291  \n",
       "16043      2.425310      2.425128      2.587086  \n",
       "\n",
       "[16044 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "artists_column = df['Symbol'].values.reshape(-1, 1)\n",
    "\n",
    "one_hot_encoded_artists = one_hot_encoder.fit_transform(artists_column)\n",
    "\n",
    "df['Symbol'] = np.argmax(one_hot_encoded_artists, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling and Spliting train,test,validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df.drop('Close', axis=1)  \n",
    "y = df['Close']\n",
    "\n",
    "# Split the dataset into training (70%), validation (15%), and test (15%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Low</th>\n",
       "      <th>Midpoint</th>\n",
       "      <th>High</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29001.720703</td>\n",
       "      <td>28803.585938</td>\n",
       "      <td>29202.106445</td>\n",
       "      <td>29600.626953</td>\n",
       "      <td>28994.009766</td>\n",
       "      <td>27362.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>29374.152344</td>\n",
       "      <td>29091.181641</td>\n",
       "      <td>31123.149414</td>\n",
       "      <td>33155.117188</td>\n",
       "      <td>29376.455078</td>\n",
       "      <td>28840.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>32127.267578</td>\n",
       "      <td>32052.316406</td>\n",
       "      <td>33330.437500</td>\n",
       "      <td>34608.558594</td>\n",
       "      <td>32129.408203</td>\n",
       "      <td>29001.720703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>32782.023438</td>\n",
       "      <td>28722.755859</td>\n",
       "      <td>31081.487305</td>\n",
       "      <td>33440.218750</td>\n",
       "      <td>32810.949219</td>\n",
       "      <td>29374.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>33992.429688</td>\n",
       "      <td>31971.914062</td>\n",
       "      <td>30221.187500</td>\n",
       "      <td>32329.388672</td>\n",
       "      <td>34437.589844</td>\n",
       "      <td>31977.041016</td>\n",
       "      <td>32127.267578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>10</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.135291</td>\n",
       "      <td>2.101517</td>\n",
       "      <td>2.132578</td>\n",
       "      <td>2.163639</td>\n",
       "      <td>2.143799</td>\n",
       "      <td>2.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>10</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.160291</td>\n",
       "      <td>2.156239</td>\n",
       "      <td>2.397342</td>\n",
       "      <td>2.638445</td>\n",
       "      <td>2.159645</td>\n",
       "      <td>2.092255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16041</th>\n",
       "      <td>10</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.587086</td>\n",
       "      <td>2.424762</td>\n",
       "      <td>2.578523</td>\n",
       "      <td>2.732283</td>\n",
       "      <td>2.592313</td>\n",
       "      <td>2.135291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>10</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.539670</td>\n",
       "      <td>2.418916</td>\n",
       "      <td>2.483391</td>\n",
       "      <td>2.547866</td>\n",
       "      <td>2.544140</td>\n",
       "      <td>2.160291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16043</th>\n",
       "      <td>10</td>\n",
       "      <td>2.344989</td>\n",
       "      <td>2.425865</td>\n",
       "      <td>2.287904</td>\n",
       "      <td>2.356607</td>\n",
       "      <td>2.425310</td>\n",
       "      <td>2.425128</td>\n",
       "      <td>2.587086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16044 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol         Close   Close_lag_1           Low      Midpoint  \\\n",
       "0           3  29374.152344  29001.720703  28803.585938  29202.106445   \n",
       "1           3  32127.267578  29374.152344  29091.181641  31123.149414   \n",
       "2           3  32782.023438  32127.267578  32052.316406  33330.437500   \n",
       "3           3  31971.914062  32782.023438  28722.755859  31081.487305   \n",
       "4           3  33992.429688  31971.914062  30221.187500  32329.388672   \n",
       "...       ...           ...           ...           ...           ...   \n",
       "16039      10      2.160291      2.135291      2.101517      2.132578   \n",
       "16040      10      2.587086      2.160291      2.156239      2.397342   \n",
       "16041      10      2.539670      2.587086      2.424762      2.578523   \n",
       "16042      10      2.425865      2.539670      2.418916      2.483391   \n",
       "16043      10      2.344989      2.425865      2.287904      2.356607   \n",
       "\n",
       "               High          Open   Close_lag_3  \n",
       "0      29600.626953  28994.009766  27362.437500  \n",
       "1      33155.117188  29376.455078  28840.953125  \n",
       "2      34608.558594  32129.408203  29001.720703  \n",
       "3      33440.218750  32810.949219  29374.152344  \n",
       "4      34437.589844  31977.041016  32127.267578  \n",
       "...             ...           ...           ...  \n",
       "16039      2.163639      2.143799      2.045980  \n",
       "16040      2.638445      2.159645      2.092255  \n",
       "16041      2.732283      2.592313      2.135291  \n",
       "16042      2.547866      2.544140      2.160291  \n",
       "16043      2.425310      2.425128      2.587086  \n",
       "\n",
       "[16044 rows x 8 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df)  # Exclude 'Date' if it exists\n",
    "\n",
    "# Define a function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length, -1]  # Assuming the target (e.g., 'Close') is the last column\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 10  # Number of time steps to look back \n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0001277220726478845\n",
      "Epoch 10, Loss: 0.0009243362001143396\n",
      "Epoch 20, Loss: 2.6332269044360146e-05\n",
      "Epoch 30, Loss: 5.427119958767435e-06\n",
      "Epoch 40, Loss: 8.535380402463488e-06\n",
      "Epoch 50, Loss: 1.5662972145946696e-05\n",
      "Epoch 60, Loss: 1.7458910406276118e-06\n",
      "Epoch 70, Loss: 1.6813366983114975e-06\n",
      "Epoch 80, Loss: 3.124770228168927e-05\n",
      "Epoch 90, Loss: 4.863154572376516e-06\n",
      "Epoch 100, Loss: 1.5159989743551705e-05\n",
      "Epoch 110, Loss: 1.8470085478838882e-06\n",
      "Epoch 120, Loss: 1.6872587593752542e-06\n",
      "Epoch 130, Loss: 0.0006334675708785653\n",
      "Epoch 140, Loss: 2.540026071073953e-05\n",
      "Epoch 150, Loss: 3.540695843184949e-06\n",
      "Epoch 160, Loss: 5.942789357504807e-06\n",
      "Epoch 170, Loss: 1.0572098290140275e-05\n",
      "Epoch 180, Loss: 0.00035983629641123116\n",
      "Epoch 190, Loss: 5.767291213487624e-07\n"
     ]
    }
   ],
   "source": [
    "# Adjust hyperparameters\n",
    "hidden_dim = 100  # Number of LSTM units\n",
    "num_layers = 4  # Number of LSTM layers\n",
    "learning_rate = 0.001  # Learning rate for the optimizer\n",
    "batch_size = 64  # Batch size for training\n",
    "weight_decay = 1e-5  # L2 regularization term\n",
    "output_dim = 1\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "\n",
    "# Define the model\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "# Define the optimizer with weight decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Define a DataLoader for batch processing\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop with batch processing and gradient clipping\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5796528884948202e-07\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "model.eval()\n",
    "predicted = model(X_test)\n",
    "predicted = predicted.detach().numpy()\n",
    "actual = y_test.numpy()\n",
    "\n",
    "# You can use any metric for evaluation, here we use Mean Squared Error as an example\n",
    "test_loss = criterion(model(X_test), y_test)\n",
    "print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "# Remember to invert the scaling for actual predictions before comparing them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reshaped = np.zeros((len(predicted), scaled_data.shape[1]))  # Create a dummy array with the same width as 'scaled_data'\n",
    "predicted_reshaped[:, -1] = predicted.squeeze()  # Assuming the target feature is the last column\n",
    "\n",
    "actual_reshaped = np.zeros((len(actual), scaled_data.shape[1]))\n",
    "actual_reshaped[:, -1] = actual.squeeze()\n",
    "\n",
    "# Step 2: Apply the inverse transformation\n",
    "predicted_inverse = scaler.inverse_transform(predicted_reshaped)[:, -1]  # Select the target column after inversion\n",
    "actual_inverse = scaler.inverse_transform(actual_reshaped)[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 26.19111101974393\n",
      "Root Mean Squared Error (RMSE): 26.854330192784424\n",
      "Mean Absolute Percentage Error (MAPE): 3595.7201740654164%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(actual_inverse, predicted_inverse)\n",
    "rmse = np.sqrt(mean_squared_error(actual_inverse, predicted_inverse))\n",
    "# MAPE function needs to handle division by zero, so we'll define it manually\n",
    "mape = np.mean(np.abs((actual_inverse - predicted_inverse) / actual_inverse)) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'actual_inverse' and 'predicted_inverse' are your actual and predicted values respectively\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(actual_inverse, label='Actual', color='blue')\n",
    "plt.plot(predicted_inverse, label='Predicted', color='red')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [916, 908]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m linear_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mlinear_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m linear_reg\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [916, 908]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Linear Regression MSE: {mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9998187610689385\n",
      "Mean Absolute Error (MAE): 30.318067887842968\n",
      "Root Mean Squared Error (RMSE): 141.21708306492204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validated MSE: 21423.389740088758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_lr = cross_val_score(linear_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_lr = -cv_scores_lr.mean()\n",
    "print(f\"Linear Regression Cross-Validated MSE: {mean_mse_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "Grid Search evaluates all the provided combinations of hyperparameters, which can be computationally expensive but thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'n_estimators': 120, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "Best score found:  195.77046215036302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [80, 100, 120, 140],\n",
    "    'max_depth': [20, 30, 40, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize the randomized search model\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the randomized search model\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", np.sqrt(-random_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 275}\n",
      "Best score found:  38651.833918261735\n",
      "Test MSE: 34268.50814304979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),  # Number of trees in the forest\n",
    "    'max_depth': randint(10, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 11),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 11),  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,  # Controls the verbosity: the higher, the more messages\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Number of jobs to run in parallel (-1 means using all processors)\n",
    "    scoring='neg_mean_squared_error'  # Change according to your needs\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9996885615588167\n",
      "Mean Absolute Error (MAE): 41.22077809745639\n",
      "Root Mean Squared Error (RMSE): 185.11755222844155\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_independent_test_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have X_independent_test and y_independent_test prepared\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_independent \u001b[38;5;241m=\u001b[39m random_forest\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_independent_test_scaled\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mse_independent \u001b[38;5;241m=\u001b[39m mean_squared_error(y_independent_test, y_pred_independent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_independent_test_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have X_independent_test and y_independent_test prepared\n",
    "y_pred_independent = random_forest.predict(X_independent_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_independent = mean_squared_error(y_independent_test, y_pred_independent)\n",
    "r2_independent = r2_score(y_independent_test, y_pred_independent)\n",
    "mae_independent = mean_absolute_error(y_independent_test, y_pred_independent)\n",
    "\n",
    "print(f\"Independent Test MSE: {mse_independent}\")\n",
    "print(f\"Independent Test R-squared: {r2_independent}\")\n",
    "print(f\"Independent Test MAE: {mae_independent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: 504017.42934379855\n",
      "Average R-squared: -17.12640306626498\n",
      "Average MAE: 211.3903191462378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize model (assuming best parameters are already set)\n",
    "model = RandomForestRegressor(\n",
    "    max_depth=12, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=2, \n",
    "    n_estimators=275,\n",
    "    random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# Calculate average scores\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE with Best Parameters: 33160.30784583442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model with the best parameters from Grid Search\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=120,  # Best number of trees\n",
    "    max_depth=30,  # Best maximum depth of trees\n",
    "    min_samples_leaf=1,  # Best minimum number of samples required at a leaf node\n",
    "    min_samples_split=2,  # Best minimum number of samples required to split an internal node\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model with the training data\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the test data\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"Random Forest MSE with Best Parameters: {mse_rf}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.999698633084885\n",
      "Mean Absolute Error (MAE): 40.328240554986756\n",
      "Root Mean Squared Error (RMSE): 182.09971951058688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_rf)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validated MSE: 96922514.69028388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_rf = cross_val_score(random_forest, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_rf = -cv_scores_rf.mean()\n",
    "print(f\"Random Forest Cross-Validated MSE: {mean_mse_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "Random Search samples a given number of candidates from a parameter space with a specified distribution. It's less comprehensive but much faster than Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Best score found:  39292.73854500158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define the parameter distribution to sample from\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample': [0.6, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xg_reg, param_distributions=param_dist, n_iter=25, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best score found: \", -random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized XGBoost MSE: 32797.58750307243\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Adjusting the model with the best parameters found\n",
    "xg_reg_optimized = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.7,  # Updated from 0.3 to 0.7 based on the best parameters\n",
    "    learning_rate=0.1,     # Remains the same as before\n",
    "    max_depth=5,           # Remains the same as before\n",
    "    alpha=10,              # Remains the same as before\n",
    "    n_estimators=500,      # Updated from 10 to 500 based on the best parameters\n",
    "    subsample=0.8          # Added based on the best parameters\n",
    ")\n",
    "\n",
    "# Fit the model with the adjusted parameters\n",
    "xg_reg_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_optimized = xg_reg_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the adjusted parameters\n",
    "mse_xgb_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "print(f\"Optimized XGBoost MSE: {mse_xgb_optimized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.9997019295533995\n",
      "Mean Absolute Error (MAE): 39.37663597807381\n",
      "Root Mean Squared Error (RMSE): 181.10104224733888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred_optimized)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_optimized)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_optimized))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-Validated MSE: 98328661.26877618\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the model\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_xgb = cross_val_score(xg_reg, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean MSE\n",
    "mean_mse_xgb = -cv_scores_xgb.mean()\n",
    "print(f\"XGBoost Cross-Validated MSE: {mean_mse_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [01:05<00:13,  1.18s/it]"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle your dataset (optional but recommended for cross-sectional data)\n",
    "#X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and compare models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the performance of each model\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/df_fs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
